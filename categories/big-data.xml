<?xml version="1.0" encoding="utf-8"?>
<?xml-stylesheet type="text/xsl" href="../assets/xml/rss.xsl" media="all"?><rss xmlns:atom="http://www.w3.org/2005/Atom" version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/"><channel><title>Tomás Delvechio (Publicaciones sobre big data)</title><link>http://tomasdelvechio.github.io/</link><description></description><atom:link type="application/rss+xml" rel="self" href="http://tomasdelvechio.github.io/categories/big-data.xml"></atom:link><language>es</language><copyright>Contents © 2018 &lt;a href="mailto:tdelvechio@unlu.edu.ar"&gt;Tomás Delvechio&lt;/a&gt; 
&lt;a rel="license" href="https://creativecommons.org/licenses/by-nc-sa/4.0/"&gt;
&lt;img alt="Creative Commons License BY-NC-SA"
style="border-width:0; margin-bottom:12px;"
src="https://i.creativecommons.org/l/by-nc-sa/4.0/88x31.png"&gt;&lt;/a&gt;</copyright><lastBuildDate>Sat, 08 Sep 2018 18:48:35 GMT</lastBuildDate><generator>Nikola (getnikola.com)</generator><docs>http://blogs.law.harvard.edu/tech/rss</docs><item><title>Introducción a Spark</title><link>http://tomasdelvechio.github.io/blog/introduccion-a-spark/</link><dc:creator>Tomás Delvechio</dc:creator><description>&lt;div&gt;&lt;p&gt;Apache Spark es un framework de procesamiento muy de moda en entornos de procesamiento para Big Data, IoT y Machine Learning.&lt;/p&gt;
&lt;h3&gt;Pipeline&lt;/h3&gt;
&lt;p&gt;El pipeline de trabajo en spark es conocido como &lt;strong&gt;DAG&lt;/strong&gt; (Directed Acyclic Graph) y se basa en armar un grafo de trabajo donde las tareas se sucedan unas a otras segun se establezca.&lt;/p&gt;
&lt;p&gt;Ademas, propone que muchas operaciones que en MapReduce involucran operaciones de entrada salida a disco, se hagan en memoria principal, lo que genera un rendimiento mayor comparado con su predecesor.&lt;/p&gt;
&lt;h3&gt;Lenguajes&lt;/h3&gt;
&lt;p&gt;Spark acepta Java, Scala, Python y R, aunque no todos estan soportados de la misma forma y de manera completa.&lt;/p&gt;
&lt;h3&gt;Otras herramientas&lt;/h3&gt;
&lt;p&gt;Spark ofrece ademas una consola interactiva para Scala, Python y R con capacidades REPL (Read, Evaluate, Print y Loop).&lt;/p&gt;
&lt;p&gt;Ademas del core, Spark ofrece algunas librerias para tareas comunes en el ambito de big data: SparkSQL, Spark Streaming, Spark MLlib y Spark GraphX.&lt;/p&gt;&lt;/div&gt;</description><category>big data</category><category>distributed systems</category><category>programming</category><category>spark</category><guid>http://tomasdelvechio.github.io/blog/introduccion-a-spark/</guid><pubDate>Sat, 08 Sep 2018 18:15:18 GMT</pubDate></item></channel></rss>